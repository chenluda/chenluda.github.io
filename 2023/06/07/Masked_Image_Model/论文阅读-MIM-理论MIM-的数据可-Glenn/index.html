<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>MIM | 理论：MIM 的数据可扩展性研究 | Glenn&#39;s blog</title>
  <meta name="description" content="题目：Delving Deeper into Data Scaling in Masked Image Modeling作者单位：字节跳动论文网址：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15248论文代码：未公开首次发布时间：2023 年 5 月 24 日  12345678@misc&amp;#123;lu2023delving,      title&#x3D;&amp;#123;Delving D">
<meta property="og:type" content="article">
<meta property="og:title" content="MIM | 理论：MIM 的数据可扩展性研究">
<meta property="og:url" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/index.html">
<meta property="og:site_name" content="Glenn">
<meta property="og:description" content="题目：Delving Deeper into Data Scaling in Masked Image Modeling作者单位：字节跳动论文网址：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15248论文代码：未公开首次发布时间：2023 年 5 月 24 日  12345678@misc&amp;#123;lu2023delving,      title&#x3D;&amp;#123;Delving D">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-74ea72fca3de3bbc6cede76cdb5b5b2d_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-4c61205631913edc903ea0181d493ec0_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-5f31807abbf48182986b5b46f87793a7_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-d448e65a0024d5cad4054cf35817dcc7_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-3b9376b97fa7b4086afd73f2a91ffcd6_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-5d56a8e3953c846b7fdb2a1cc0ecd8b2_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-f5d1ca2df98d78e471dac0d8b0a9ae24_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-35ad4cf7288df1c554eac09be06feabd_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-39ac709b50343df248d19b780eed4a1d_r.jpg">
<meta property="og:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-12fff7f87139db14d994eb45ecb31027_r.jpg">
<meta property="article:published_time" content="2023-06-07T10:38:27.000Z">
<meta property="article:modified_time" content="2023-06-07T10:47:57.473Z">
<meta property="article:author" content="Glenn">
<meta property="article:tag" content="Masked Image Modeling">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-74ea72fca3de3bbc6cede76cdb5b5b2d_r.jpg">
  <!-- Canonical links -->
  <link rel="canonical" href="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Glenn" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/avatar.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/chenluda" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.png" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">Glenn</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Stay hungry, stay foolish.</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Yunnan, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/chenluda" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://www.zhihu.com/people/Glenn" target="_blank" title="Zhihu" data-toggle=tooltip data-placement=top><i class="icon icon-zhihu"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>① <strong>google，chatgpt</strong> 账号注册</p> <p>② <strong>chatgpt</strong> 账号升级 <strong>plus</strong></p> <p><strong>联系 wx：GlennChen2021</strong></p> <img src="/images/chatgpt.jpg" width="200" height="200">
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B9%A6%E7%B1%8D/">书籍</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BB%A3%E7%A0%81/">代码</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A8%E8%8D%90/">推荐</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a><span class="category-list-count">19</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Competition/" style="font-size: 13px;">Competition</a> <a href="/tags/Masked-Image-Modeling/" style="font-size: 14px;">Masked Image Modeling</a> <a href="/tags/Medical-Image-Segmentation/" style="font-size: 13.25px;">Medical Image Segmentation</a> <a href="/tags/Research/" style="font-size: 13.75px;">Research</a> <a href="/tags/Steve-Jobs/" style="font-size: 13.5px;">Steve Jobs</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a><span class="archive-list-count">23</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%8E%A8%E8%8D%90/">推荐</a>
              </p>
              <p class="item-title">
                <a href="/2023/06/07/%E9%80%9F%E8%A7%88/us%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%BA%94%E7%94%A8%E4%BB%8E%E8%87%AA%E7%84%B6%E5%88%B0%E7%A7%91%E5%AD%A6%E7%95%85%E8%A1%8C%E7%A7%91%E7%A0%94%E5%AE%87-Glenn/" class="title">Catalyst Plus：从入门到应用，从自然到科学，畅行科研宇宙</a>
              </p>
              <p class="item-date">
                <time datetime="2023-06-07T11:29:23.000Z" itemprop="datePublished">2023-06-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
              </p>
              <p class="item-title">
                <a href="/2023/06/07/Medical_Image_Segmentaion/Seg-%E8%85%B9%E9%83%A8%E5%A4%9A%E5%99%A8%E5%AE%98%E5%92%8C%E8%82%BF%E7%98%A4%E5%88%86%E5%89%B2%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AD%A6-Glenn/" class="title">MedSeg | 腹部多器官和肿瘤分割的增量学习</a>
              </p>
              <p class="item-date">
                <time datetime="2023-06-07T10:58:37.000Z" itemprop="datePublished">2023-06-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
              </p>
              <p class="item-title">
                <a href="/2023/06/07/Medical_Image_Segmentaion/IFE%E5%9F%BA%E4%BA%8E%E6%9B%B2%E7%8E%87%E6%88%96%E4%BF%A1%E6%81%AF%E7%86%B5%E7%9A%84%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA-Glenn/" class="title">MedSeg | IFE：基于曲率或信息熵的通道注意力机制</a>
              </p>
              <p class="item-date">
                <time datetime="2023-06-07T10:58:29.000Z" itemprop="datePublished">2023-06-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
              </p>
              <p class="item-title">
                <a href="/2023/06/07/Medical_Image_Segmentaion/Loss%E7%94%A8%E4%BA%8E%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E9%B2%81%E6%A3%92%E6%8D%9F%E5%A4%B1%E5%87%BD-Glenn/" class="title">MedSeg | T-Loss：用于医学图像分割的鲁棒损失函数</a>
              </p>
              <p class="item-date">
                <time datetime="2023-06-07T10:58:29.000Z" itemprop="datePublished">2023-06-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
              </p>
              <p class="item-title">
                <a href="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9D%8E%E9%A3%9E%E9%A3%9E-MIM-SiamMAE-Glenn/" class="title">MIM | SiamMAE：用于从视频中学习视觉对应关系的 MAE 简单扩展</a>
              </p>
              <p class="item-date">
                <time datetime="2023-06-07T10:51:29.000Z" itemprop="datePublished">2023-06-07</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
  <aside class="sidebar sidebar-toc collapse   in  " id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="toc-number">1.</span> <span class="toc-text">主要内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E4%B8%8E%E7%BB%93%E6%9E%9C"><span class="toc-number">2.</span> <span class="toc-text">方法与结果</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84%E9%87%8D%E5%BB%BA%E7%9B%AE%E6%A0%87%E7%A0%94%E7%A9%B6"><span class="toc-number">2.1.</span> <span class="toc-text">不同的重建目标研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%A7%84%E6%A8%A1%E7%A0%94%E7%A9%B6"><span class="toc-number">2.2.</span> <span class="toc-text">预训练数据集规模研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%B4%A8%E9%87%8F%E7%A0%94%E7%A9%B6"><span class="toc-number">2.3.</span> <span class="toc-text">预训练数据集质量研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E9%9A%BE%E7%9A%84%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E7%A0%94%E7%A9%B6"><span class="toc-number">2.4.</span> <span class="toc-text">更难的下游任务研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E5%BC%BA%E7%9A%84%E7%9B%AE%E6%A0%87%E7%BC%96%E7%A0%81%E5%99%A8%E7%A0%94%E7%A9%B6"><span class="toc-number">2.5.</span> <span class="toc-text">更强的目标编码器研究</span></a></li></ol></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-Masked_Image_Model/论文阅读-MIM-理论MIM-的数据可-Glenn" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      MIM | 理论：MIM 的数据可扩展性研究
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/" class="article-date">
	  <time datetime="2023-06-07T10:38:27.000Z" itemprop="datePublished">2023-06-07</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/Masked-Image-Modeling/" rel="tag">Masked Image Modeling</a>
  </span>


        

	<span class="article-read hidden-xs">
    	<i class="icon icon-eye-fill" aria-hidden="true"></i>
    	<span id="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/" class="leancloud_visitors"  data-flag-title="MIM | 理论：MIM 的数据可扩展性研究">
			<span class="leancloud-visitors-count">0</span>
		</span>
    </span>

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-74ea72fca3de3bbc6cede76cdb5b5b2d_r.jpg"></p>
<blockquote>
<p><em><strong>题目：</strong>Delving Deeper into Data Scaling in Masked Image Modeling</em><br><em><strong>作者单位：</strong>字节跳动</em><br><em><strong>论文网址：</strong><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2305.15248">https://arxiv.org/abs/2305.15248</a></em><br><em><strong>论文代码：</strong>未公开</em><br><em><strong>首次发布时间：</strong>2023 年 5 月 24 日</em></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@misc&#123;lu2023delving,</span><br><span class="line">      title=&#123;Delving Deeper into Data Scaling in Masked Image Modeling&#125;, </span><br><span class="line">      author=&#123;Cheng-Ze Lu and Xiaojie Jin and Qibin Hou and Jun Hao Liew and Ming-Ming Cheng and Jiashi Feng&#125;,</span><br><span class="line">      year=&#123;2023&#125;,</span><br><span class="line">      eprint=&#123;2305.15248&#125;,</span><br><span class="line">      archivePrefix=&#123;arXiv&#125;,</span><br><span class="line">      primaryClass=&#123;cs.CV&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<hr>
<h1 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h1><p>使用 Coyo-700M 替代常用的 ImageNet（手动处理和以对象为中心） 数据集来探索 MIM 的数据缩放能力（可扩展性），实验结果表明：</p>
<p>1）当训练数据的规模相对较小时，MIM 可以被视为提高 model capacity 的有效方法； </p>
<p>2）更强的重建目标可以增加模型在下游任务上的性能； </p>
<p>3）MIM 预训练在大多数情况下与数据无关，这意味着采样预训练数据的策略并不重要。</p>
<hr>
<h1 id="方法与结果"><a href="#方法与结果" class="headerlink" title="方法与结果"></a>方法与结果</h1><p>如图 1 所示，作者基于 MAE 设计了一个 MIM 基本框架，将 MAE 的重建目标像素值换成目标编码器的输出，此时，重建损失为：</p>
<p>{\mathcal L}_{r}&#x3D;\frac{\left(\overline{y}_{c l s}^{t}-\overline{y}_{c l s}^{s}\right)^{2}+\sum_{i&#x3D;1}^{N}(\overline{y}_{i}^{t}-\overline{y}_{i}^{s})^{2}}{N+1} </p>
<p>其中， \overline{y}^{t} 和 \overline{y}^{s} 表示目标编码器和解码器的 l_2 归一化输出。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-4c61205631913edc903ea0181d493ec0_r.jpg"><br>图1. MIM 基本框架</p>
<h2 id="不同的重建目标研究"><a href="#不同的重建目标研究" class="headerlink" title="不同的重建目标研究"></a>不同的重建目标研究</h2><p>首先使用 ImageNet-1k 和 ImageNet-22k 作为预训练数据集来研究不同重建目标带来的影响。</p>
<p>选择以<strong>纯 MIM 方式进行预训练的 MAE</strong>、<strong>以纯基于增强的对比学习方式进行预训练的 DINO</strong>、<strong>在 MIM 和对比学习的组合下进行预训练的 CMAE</strong> 和<strong>使用语言辅助进行预训练的 CLIP</strong> 等自监督方法作为目标编码器来生成重建目标。使用 RGB 图像像素值作为目标的原始 MAE 被当作 baseline。结果如表 1 所示。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-5f31807abbf48182986b5b46f87793a7_r.jpg"><br>表1. 使用不同目标编码器的不同下游任务的结果。<br><strong>当预训练数据集从 ImageNet-1k 更改为 ImageNet-22k 时，这导致图像数量从 ~1M 增加到 ~14M，我们可以观察到下游任务的性能显着提高，尤其是在密集预测任务上。</strong>例如，当 CMAE 被用作 ImageNet-22k 上的目标编码器时，与在 ImageNet-1k 上预训练的模型相比，在 AP^{box} 和 AP^{mask} 方面可以获得 ~0.6% 和 ~0.6% 的性能增益。</p>
<p>在大多数情况下，使用 CLIP 预训练的模型会产生更好的结果。例如，在 ImageNet1k 上，模型在 ImageNet-22k 数据集上进行预训练时可以达到 84.77% 的 Top-1 准确率，比 baseline 高 1.87%（84.77% 对 82.90%）。</p>
<p>此外，在预训练期间使用 CLIP 作为目标编码器的模型表现出更好的数据缩放能力。具体来说，在 CLIP 的辅助下，在 ImageNet-1k 上的性能提高了 84.40%→84.77%(+0.4%)，在 CityScapes 上的性能提高了80.47%→81.72%(+1.25%)。以上实验结果表明，<strong>CLIP 是 MIM 预训练的强目标编码器</strong>，因此作者选择CLIP 作为目标编码器进行以下实验。</p>
<h2 id="预训练数据集规模研究"><a href="#预训练数据集规模研究" class="headerlink" title="预训练数据集规模研究"></a>预训练数据集规模研究</h2><p>ImageNet-1k 数据集是以对象为中心的，这与现实场景不一致。因此，作者选择包含大规模信息图像-文本对的 Coyo-700M 作为预训练数据集进行进一步研究。</p>
<p>图 2 中可视化了不同大小的预训练数据集对不同下游任务的影响，定量结果如表 2、表 3 和表 4 所示。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-d448e65a0024d5cad4054cf35817dcc7_r.jpg"><br>图2. 使用不同大小的预训练数据集在不同下游任务上的微调性能。下游任务包括 ImageNet-1k 分类、COCO 对象检测、ADE20K 语义分割和 CityScapes 语义分割。<br>从图 2 中，我们可以很容易地观察到，微调性能在五个下游任务上都会饱和。</p>
<ul>
<li>当预训练数据集的大小从 0.5M 增加到 1M 时，模型的性能突然提高。</li>
<li>当预训练数据集的大小在 1M 到 10M 的范围内时，在大多数情况下仍然可以持续提高性能，但性能饱和的迹象开始出现。</li>
<li>最后，当预训练数据集的大小达到 100M 时，大多数下游任务的性能几乎没有提高，在某些情况下性能下降。</li>
</ul>
<p>我们可以得出结论，<strong>当预训练数据集的大小限制为 10M 时，该模型具有很强的数据可扩展性。然而，随着预训练数据集的大小继续增加，基于 MIM 的预训练很难为模型提供可扩展性。</strong></p>
<p>此外，对于 ViT-H 模型，我们观察到它有时会产生比 ViT-L 模型更差的结果，尤其是当使用小数据集进行预训练时。例如，当使用 0.5M 图像进行预训练时，ViT-H 在 ImageNet-1k 上实现了 82.00% 的 Top-1 精度，这比ViT-L 模型低了近 0.2%。作者推测，<strong>庞大的模型仍然需要大规模的预训练数据集来实现更好的性能，但它们仍然无法突破性能饱和的极限。</strong></p>
<p>我们还在 ImageNet-1k 上采用线性探测来评估模型是否可以用更大的预训练数据集进行扩展。线性探测结果如表 2 所示。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-3b9376b97fa7b4086afd73f2a91ffcd6_r.jpg"><br>表2. ImageNet-1k 上的微调和线性探测结果。模型在从 Coyo-700M 随机采样的不同大小的数据集上预训练模型<br>在线性探测下，当预训练数据域与验证集不同时，预训练数据集的规模起着重要的作用。当预训练数据大小较小时，学习表示和验证集之间存在差距，导致性能不佳（例如，预训练数据集规模为 0.5M 时，ViT-H 达到 36.43%）。随着尺寸扩大到 5M，线性探测的性能急剧增加，达到了 20% 以上的准确率增益。尽管如此，当预训练数据达到 100M 时，MIM 预训练显示出有限的性能改进。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-5d56a8e3953c846b7fdb2a1cc0ecd8b2_r.jpg"><br>表3. Microsoft COCO 上的对象检测和实例分割结果<br><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-f5d1ca2df98d78e471dac0d8b0a9ae24_r.jpg"><br>表4. ADE20K 和 CityScapes 上的语义分割结果</p>
<h2 id="预训练数据集质量研究"><a href="#预训练数据集质量研究" class="headerlink" title="预训练数据集质量研究"></a>预训练数据集质量研究</h2><p>如表 2 所示，使用 Coyo-1M 进行预训练最终在 ImageNet-1k 上实现了 83.17% 的 Top-1 准确度，远低于使用 ImageNet-1k 预训练的模型（83.17% vs. 84.40%），可以推测使用来自同一域的数据进行预训练和验证会导致性能差距，预训练数据的质量起着重要作用。</p>
<p>为了评估数据缩放能力是否受到预训练数据质量的影响，作者使用 CiT 中提出的采样策略，而不是随机抽样从 Coyo-700M 中选择图像进行预训练。</p>
<p>CiT 测量元数据和原始数据之间的文本嵌入的相似性，并以在线方式选择与感兴趣的任务相关的训练数据。作者采用 EVA 中的文本编码器，并比较了 Coyo-700M 数据集提供的文本描述与来自 ImageNet-1k 的类标签之间的相似性。设置不同的阈值以离线方式对不同尺度的预训练数据集进行采样。</p>
<p>如表 5 所示，<strong>CiT 采样策略不会导致任何性能改进。</strong></p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-35ad4cf7288df1c554eac09be06feabd_r.jpg"><br>表5. 微调 ViT-L&#x2F;16 并报告不同数据采样策略的结果。结果以“A&#x2F;B”格式显示，其中“A”表示随机采样，“B”表示 CiT 中提出的策略。</p>
<ul>
<li>假设 MIM 预训练是数据不可知的，这意味着预训练数据是否简单或复杂不会影响性能。</li>
<li>同时，“更好”的数据采样策略不会改变数据缩放的趋势。随着 CiT 的采样策略，ViT-L 可以获得从 Coyo-1M 到 Coyo-10M（即 84.59% → 86.20%）的 ImageNet-1k 的性能增益，而当大小增长到 100M 时，性能几乎冻结（即 86.20% → 86.22%）。</li>
</ul>
<h2 id="更难的下游任务研究"><a href="#更难的下游任务研究" class="headerlink" title="更难的下游任务研究"></a>更难的下游任务研究</h2><p>为了探索下游任务是否限制了大规模预训练模型的容量，作者尝试在“更难”的下游任务上构建和评估 MIM，包括 ImageNet-5k 上的分类、iNaturalist2018 上的长尾分类、LVIS 上的长尾对象检测。结果如表 6 和表 7 所示。</p>
<p>从表 6 中可以看出，在包含比 ImageNet-1k 更多类的 ImageNet-5k 上，可以很容易地发现：</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-39ac709b50343df248d19b780eed4a1d_r.jpg"><br>表6. 对“更难”下游任务进行微调或使用更强的目标编码器的结果。</p>
<ul>
<li>当数据大小扩大到 10M 时，微调性能会迅速提高（59.09% 对 58.01%）；</li>
<li>然而，当数据大小扩大到 100M 时，模型仅实现了约 0.3% 的性能提升（59.09% 对 59.38%）。</li>
</ul>
<p>这种现象与在 ImageNet-1k 上微调时观察到的趋势一致。</p>
<p>此外，还在 iNaturalist2018 细粒度图像分类上评估 VT-L&#x2F;16，并观察到类似的结论。</p>
<p>请注意，在表 6 中，使用 Coyo-5M 进行预训练的性能甚至超过了使用 Coyo-10M 的性能（81.09% 对 80.61%）。作者认为，主要原因是 Coyo-5M 预训练的模型经过更多的迭代训练。</p>
<p>图 7 报告了 LVIS 的结果，这是一个具有挑战性的数据集，具有大词汇量对象类别以及高质量的实例掩码。与 COCO 不同，LVIS 包含大量稀有类别。</p>
<p><img src="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/v2-12fff7f87139db14d994eb45ecb31027_r.jpg"><br>图7. 在 LVIS 验证集上评估的 ViT-L&#x2F;16 的定量结果。“r”、“c”和“f”分别代表“rare”、“common”和“frequency”。MIM 预训练很少在稀有类别上表现出很强的数据可扩展性。</p>
<ul>
<li>从表 7 中，可以观察到使用更大的数据集进行预训练，该模型可以显着提高性能。具体来说，ViT-L 使用预训练的 Coyo-100M 实现了 47.30% 的最佳 APbox，比使用 Coyo-10M 预训练的模型的性能高 0.98%（47.30% vs. 46.32%）。</li>
<li>此外，性能增益主要来自稀有类别。当数据集的大小从 10M 增加到 100M 时，稀有类的性能提高了 3% 以上（36.51% → 39.83%），而频繁类的性能仅增加了不到 1%（50.93% → 51.59%），这表明大规模数据预训练可能有助于长尾目标检测以及实例分割。</li>
</ul>
<h2 id="更强的目标编码器研究"><a href="#更强的目标编码器研究" class="headerlink" title="更强的目标编码器研究"></a>更强的目标编码器研究</h2><p>使用 VT-B&#x2F;16 作为目标编码器是对训练成本的折衷，这可能会限制模型的数据可扩展性。因此，作者还尝试了更大的目标编码器进行重建，包括来自 CLIP 的 VT-L&#x2F;14（<del>650M 参数），以及来自 EVA 的 EVA-G&#x2F;14（</del>1B 参数）。结果列于表6。</p>
<p>当使用 100M 数据进行预训练时，使用 CLIP-L&#x2F;14 实现了 86.66% 的 Top-1 准确度，这比使用 CLIP-B&#x2F;16 预训练的模型高出约 0.4%。但是，这可能是由于 patch 大小的差异造成的。</p>
<p>在这里，作者使用更强的目标编码器 EVA-G&#x2F;14，大约有 1.0B 参数，用于重建，它达到了 86.94% 的 Top-1 准确度，比使用 CLIP-L&#x2F;14 预训练的模型高约 0.3%（86.94% 与 86.66%）。</p>
<p>因此，<strong>作者认为使用更强大的目标编码器可能有助于增加模型的容量。</strong></p>
<p>然后，为了调查较长的预训练是否有助于提高性能，作者使用 100M 数据预训练具有 10 个 epoch 的编码器。该模型达到 86.90%，与用 15 个 epoch 预训练的模型相似（86.90% 对 86.94%）。</p>
<p>换句话说，<strong>当性能趋于饱和时，即使使用更长的预训练时期，也很难提高性能。</strong></p>
<p>最后，作者使用包含 ~1B 参数的 EVA-G&#x2F;14 作为目标编码器来探索以 MIM 方式预训练的编码器是否在数据上可扩展。</p>
<p>不幸的是，获得了相同的结论，即当模型大小固定时，使用 MIM 的模型很难在更多的预训练数据上进行扩展。</p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://chenluda.github.io/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-%E7%90%86%E8%AE%BAMIM-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF-Glenn/" title="MIM | 理论：MIM 的数据可扩展性研究" target="_blank" rel="external">https://chenluda.github.io/2023/06/07/Masked_Image_Model/论文阅读-MIM-理论MIM-的数据可-Glenn/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/chenluda" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.png" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/chenluda" target="_blank"><span class="text-dark">Glenn</span><small class="ml-1x">Stay hungry, stay foolish.</small></a></h3>
        <div>咖啡，健身，热爱生活。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2023/06/07/Masked_Image_Model/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-MIM-MR-MAE%E5%AE%8C%E7%BE%8E%E5%88%A9%E7%94%A8-Glenn/" title="MIM | MR-MAE：完美利用 MIM 的高级与低级特征"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2023/05/13/%E4%B9%A6%E7%B1%8D/Steve%E5%85%B3%E4%BA%8E%E7%AB%A5%E5%B9%B4%E5%92%8C%E9%9D%92%E5%B9%B4%E6%97%B6%E6%9C%9F%E7%9A%84%E5%9B%9E%E5%BF%86/" title="Make Something Wonderful 全书翻译：Steve 关于童年和青年时期的回忆（1）"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn " data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">    <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  


</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/chenluda" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://www.zhihu.com/people/Glenn" target="_blank" title="Zhihu" data-toggle=tooltip data-placement=top><i class="icon icon-zhihu"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        &copy; 2023 Glenn
        
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'rSq08S6gdVroDI1A4r7XWnix-MdYXbMMI',
    appKey: '5UM6jz8DwNaaEQTN5ojTHB1N',
    placeholder: '请输入...',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: true
  });
  </script>

     







</body>
</html>